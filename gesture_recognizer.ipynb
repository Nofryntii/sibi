{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nofryntii/sibi/blob/main/gesture_recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "id": "_GQbaiSDNXGA",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install mediapipe-model-maker"
      ],
      "metadata": {
        "id": "ZkdpuopONkKn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "from mediapipe_model_maker.python.vision import gesture_recognizer\n",
        "from mediapipe.tasks.python.vision.gesture_recognizer import GestureRecognizer\n",
        "from mediapipe.framework.formats import landmark_pb2\n"
      ],
      "metadata": {
        "id": "4ngwxmXFMtw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TbTfCL_rOLXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_root = pathlib.Path(\"/content/drive/MyDrive/Sibi\")"
      ],
      "metadata": {
        "id": "2UNyB0qcOT_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import utils"
      ],
      "metadata": {
        "id": "MJ8GP_mKOhuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan label dari dataset\n",
        "labels = [p.name for p in dataset_root.iterdir() if p.is_dir()]\n",
        "print(f\"Classes: {labels}\")\n",
        "\n",
        "# Mendapatkan daftar file gambar\n",
        "train_files = utils.find_images(dataset_root)\n",
        "print(f\"Number of training images: {len(train_files)}\")\n"
      ],
      "metadata": {
        "id": "lQmAxyg3O1R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_and_convert_images(dataset_path):\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                img_path = os.path.join(root, file)\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    # Konversi ke RGB\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    # Resize gambar ke ukuran yang diinginkan\n",
        "                    img = cv2.resize(img, (192, 192))\n",
        "                    # Simpan kembali\n",
        "                    cv2.imwrite(img_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "# Jalankan fungsi konversi\n",
        "check_and_convert_images(dataset_root)"
      ],
      "metadata": {
        "id": "nLu6nN_RytJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def check_and_convert_images(dataset_path):\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                img_path = os.path.join(root, file)\n",
        "\n",
        "                # Membaca gambar\n",
        "                img = cv2.imread(img_path)\n",
        "\n",
        "                if img is not None:\n",
        "                    # Cek jumlah channel gambar\n",
        "                    if len(img.shape) == 2:  # Jika gambar grayscale (1 channel)\n",
        "                        print(f\"Gambar grayscale terdeteksi: {img_path}\")\n",
        "                        # Konversi gambar grayscale menjadi RGB\n",
        "                        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "                    elif img.shape[2] == 3:  # Jika gambar berwarna (3 channel)\n",
        "                        # Konversi dari BGR ke RGB\n",
        "                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                    # Resize gambar ke ukuran yang diinginkan\n",
        "                    img = cv2.resize(img, (192, 192))\n",
        "\n",
        "                    # Simpan kembali gambar dengan format BGR\n",
        "                    cv2.imwrite(img_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "# Jalankan fungsi konversi\n",
        "dataset_root = \"/content/drive/MyDrive/Sibi\"\n",
        "check_and_convert_images(dataset_root)\n"
      ],
      "metadata": {
        "id": "y6fKVO6hqh9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_dataset_structure(dataset_path):\n",
        "    # Pastikan folder dataset ada\n",
        "    if not os.path.exists(dataset_path):\n",
        "        raise ValueError(f\"Dataset path {dataset_path} tidak ditemukan\")\n",
        "\n",
        "    # Variabel untuk menghitung total gambar\n",
        "    total_images = 0\n",
        "\n",
        "    # Hitung jumlah gambar per kelas\n",
        "    for class_name in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            n_images = len([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "            print(f\"Kelas {class_name}: {n_images} gambar\")\n",
        "            # Tambahkan jumlah gambar ke total\n",
        "            total_images += n_images\n",
        "\n",
        "    # Tampilkan total keseluruhan gambar\n",
        "    print(f\"\\nTotal keseluruhan gambar: {total_images} gambar\")\n",
        "\n",
        "# Menjalankan fungsi untuk memeriksa dataset\n",
        "verify_dataset_structure(dataset_root)\n"
      ],
      "metadata": {
        "id": "p5riBeKUt29u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import shutil\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def split_dataset(input_root, output_root, splits=\"80:20\", seed=None):\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    input_root = pathlib.Path(input_root)\n",
        "    output_root = pathlib.Path(output_root)\n",
        "\n",
        "    # Membagi persentase menjadi angka\n",
        "    split_percentages = [int(s) for s in splits.split(':')]\n",
        "\n",
        "    # Memastikan persentase berjumlah 100\n",
        "    assert sum(split_percentages) == 100, \"Total persentase harus 100\"\n",
        "\n",
        "    for labelpath in input_root.iterdir():\n",
        "        if not labelpath.is_dir():\n",
        "            continue\n",
        "\n",
        "        files = sorted(labelpath.iterdir())\n",
        "        np.random.shuffle(files)\n",
        "\n",
        "        # Hitung jumlah gambar untuk setiap split\n",
        "        total_files = len(files)\n",
        "        train_size = int(total_files * (split_percentages[0] / 100))\n",
        "        test_size = total_files - train_size\n",
        "\n",
        "        # Membagi dataset\n",
        "        subsets = {\n",
        "            'train': files[:train_size],\n",
        "            'test': files[train_size:]\n",
        "        }\n",
        "\n",
        "        # Menyimpan dataset ke folder output\n",
        "        for split_name, subset_files in subsets.items():\n",
        "            subset_root = output_root / split_name / labelpath.name\n",
        "            subset_root.mkdir(parents=True, exist_ok=True)\n",
        "            for file in subset_files:\n",
        "                shutil.copy(file, subset_root)\n",
        "\n",
        "        print(f\"Kelas {labelpath.name} - Train: {train_size}, Test: {test_size}\")\n",
        "\n",
        "# Menjalankan fungsi split dengan 80% untuk training dan 20% untuk testing\n",
        "output_root = \"/content/processed_data\"\n",
        "split_dataset(dataset_root, output_root, splits=\"80:20\", seed=42)\n"
      ],
      "metadata": {
        "id": "KLLqsG2XO6AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(input_root, output_root, splits=\"80:20\", seed=None):\n",
        "    np.random.seed(seed)\n",
        "    input_root, output_root = pathlib.Path(input_root), pathlib.Path(output_root)\n",
        "    split_percentages = [int(s) for s in splits.split(':')]\n",
        "    assert sum(split_percentages) == 100, \"Total persentase harus 100\"\n",
        "\n",
        "    for labelpath in input_root.iterdir():\n",
        "        if labelpath.is_dir():\n",
        "            files = sorted(labelpath.iterdir())\n",
        "            np.random.shuffle(files)\n",
        "            train_size = int(len(files) * (split_percentages[0] / 100))\n",
        "            subsets = {'train': files[:train_size], 'test': files[train_size:]}\n",
        "\n",
        "            for split_name, subset_files in subsets.items():\n",
        "                (output_root / split_name / labelpath.name).mkdir(parents=True, exist_ok=True)\n",
        "                for file in subset_files:\n",
        "                    shutil.copy(file, output_root / split_name / labelpath.name)\n",
        "\n",
        "            print(f\"Kelas {labelpath.name} - Train: {train_size}, Test: {len(files) - train_size}\")\n",
        "\n",
        "# Usage\n",
        "split_dataset(dataset_root, \"/content/processed_data\", splits=\"80:20\", seed=42)\n"
      ],
      "metadata": {
        "id": "Oqj2HlBaVOdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = gesture_recognizer.Dataset.from_folder(str(dataset_root))\n",
        "train_data.gen_tf_dataset().unbatch().save(\"/content/train_data\")"
      ],
      "metadata": {
        "id": "pxMsTp7-RecP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_root = pathlib.Path(\"/content/processed_data\")"
      ],
      "metadata": {
        "id": "DJQ5WNiCZO7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import numpy as np\n",
        "\n",
        "import utils\n",
        "\n",
        "data_root = pathlib.Path(\"./processed_data\")\n",
        "dataset_train = data_root / \"train\"\n",
        "trainfiles = utils.find_images(dataset_train)\n",
        "\n",
        "sample_files = np.random.choice(np.asarray(trainfiles), 10)\n",
        "fig, axarr = utils.plot_image_files(sample_files, ncols=5)\n",
        "fig.savefig(\"example-output.jpg\", dpi=150, bbox_inches=\"tight\")"
      ],
      "metadata": {
        "id": "aDwaujag63qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VFHzSQFh62tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mediapipe_model_maker.python.vision import gesture_recognizer\n",
        "\n",
        "handparams = gesture_recognizer.HandDataPreprocessingParams(\n",
        "    min_detection_confidence=0.5\n",
        ")\n",
        "\n",
        "dataset_train = data_root / \"train\"\n",
        "data = gesture_recognizer.Dataset.from_folder(str(dataset_train), handparams)\n",
        "train_data, validation_data = data.split(0.8)\n",
        "\n",
        "dataset_test = data_root / \"test\"\n",
        "test_data = gesture_recognizer.Dataset.from_folder(\n",
        "    str(dataset_test), handparams\n",
        ")\n"
      ],
      "metadata": {
        "id": "XeTn3-RoUo_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainfiles = utils.find_images(dataset_train)\n",
        "\n",
        "sample_files = np.random.choice(np.asarray(trainfiles), 10)\n",
        "fig, axarr = utils.plot_image_files(sample_files, ncols=5)\n",
        "fig.savefig(\"outputdataset.jpg\", dpi=150, bbox_inches=\"tight\")"
      ],
      "metadata": {
        "id": "qTqpjm80WrNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hparams = gesture_recognizer.HParams(\n",
        "    export_dir=\"exported_model\",\n",
        "    batch_size=32,\n",
        "    epochs=100,\n",
        "    shuffle=True,\n",
        "    learning_rate=0.001,\n",
        "    lr_decay=0.95,\n",
        ")\n",
        "moptions = gesture_recognizer.ModelOptions(dropout_rate=0.05)\n",
        "options = gesture_recognizer.GestureRecognizerOptions(\n",
        "    hparams=hparams, model_options=moptions\n",
        ")\n",
        "\n",
        "model = gesture_recognizer.GestureRecognizer.create(\n",
        "    train_data=train_data, validation_data=validation_data, options=options\n",
        ")\n"
      ],
      "metadata": {
        "id": "2bS8AvXcWdMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(test_data, batch_size=1)\n",
        "print(f\"Test loss: {loss:.4f}, Test accuracy: {acc:.2%}\")"
      ],
      "metadata": {
        "id": "0V6OCj8JSMmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.export_model(\"model.task\")"
      ],
      "metadata": {
        "id": "kmcb1tQxcI28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_root = pathlib.Path(\"/content/processed_data/test\")\n",
        "testfiles = list(dataset_root.glob(\"**/*.jpg\"))  # Semua file JPG dalam dataset"
      ],
      "metadata": {
        "id": "sEQ3X2BygS9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = np.random.choice(testfiles)"
      ],
      "metadata": {
        "id": "wWF1geOlg1UW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(testfiles), testfiles[:10])  # Periksa jumlah dan contoh file gambar"
      ],
      "metadata": {
        "id": "vbAHQLBIhZDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp\n",
        "from mediapipe.tasks.python.vision.gesture_recognizer import GestureRecognizer\n",
        "\n",
        "base_options = mp.tasks.BaseOptions(\n",
        "    model_asset_path=hparams.export_dir + \"/model.task\"\n",
        ")\n",
        "options = mp.tasks.vision.GestureRecognizerOptions(\n",
        "    base_options=base_options, running_mode=mp.tasks.vision.RunningMode.IMAGE\n",
        ")\n",
        "\n",
        "with GestureRecognizer.create_from_options(options) as recognizer:\n",
        "    mp_image = mp.Image.create_from_file(str(filename))\n",
        "    result = recognizer.recognize(mp_image)\n"
      ],
      "metadata": {
        "id": "B_D6wKF6c6_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples = np.random.choice(np.asarray(testfiles), 10)\n",
        "\n",
        "with GestureRecognizer.create_from_options(options) as recognizer:\n",
        "    fig, axarr = utils.plot_recognizer_predictions(test_samples, recognizer, 5)\n",
        "fig.savefig(\"example-output.jpg\", dpi=150, bbox_inches=\"tight\")"
      ],
      "metadata": {
        "id": "7Pyn-8jmg6RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "AwvZHSufhBPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm  # Tambahkan ini jika belum ada\n",
        "\n",
        "test_results = []\n",
        "with mp.tasks.vision.GestureRecognizer.create_from_options(options) as recognizer:\n",
        "    for filename in tqdm(testfiles, desc=\"Processing test files\"):\n",
        "        mp_image = mp.Image.create_from_file(str(filename))\n",
        "        result = recognizer.recognize(mp_image)\n",
        "        if len(result.gestures) > 0:\n",
        "            pred = result.gestures[0][0].category_name or \"n/a\"\n",
        "        else:\n",
        "            pred = \"empty\"\n",
        "        test_results.append((filename, filename.parent.name, pred))\n",
        "\n",
        "# Convert to DataFrame\n",
        "results_df = pd.DataFrame(test_results, columns=[\"filename\", \"label\", \"pred\"])\n"
      ],
      "metadata": {
        "id": "nSaBkNo1c_p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import numpy as np\n",
        "import sklearn\n",
        "\n",
        "# Menentukan urutan kelas\n",
        "classes = sorted(test_data.label_names + [\"n/a\", \"empty\"])\n",
        "\n",
        "# Menghitung confusion matrix tanpa normalisasi\n",
        "cm = sklearn.metrics.confusion_matrix(\n",
        "    results_df[\"label\"], results_df[\"pred\"], labels=classes\n",
        ")\n",
        "\n",
        "# Membuat objek ConfusionMatrixDisplay\n",
        "disp = sklearn.metrics.ConfusionMatrixDisplay(cm, display_labels=classes)\n",
        "\n",
        "# Membuat figure dan axis\n",
        "fig, ax = plt.subplots()  # Menyesuaikan ukuran untuk visualisasi lebih baik\n",
        "\n",
        "# Plot confusion matrix tanpa grid\n",
        "disp.plot(include_values=False, cmap=\"Blues\", ax=ax)\n",
        "ax.grid(False)\n",
        "ax.set_facecolor(\"white\")\n",
        "\n",
        "# Menambahkan nilai pada sel, hanya jika tidak nol, dengan warna abu-abu\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        if cm[i, j] != 0:  # Menampilkan nilai hanya jika bukan nol\n",
        "            ax.text(\n",
        "                j, i, f\"{cm[i, j]}\",\n",
        "                ha=\"center\", va=\"center\", color=\"gold\", fontsize=8\n",
        "            )\n",
        "\n",
        "# Menyimpan plot ke file dan menampilkannya\n",
        "plt.savefig(\"confusion_matrix_filtered_gray_text.png\", dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ILAKMIpRbzNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
        "\n",
        "# Menambahkan kolom 'result' untuk mengevaluasi apakah prediksi benar atau salah\n",
        "results_df[\"result\"] = results_df[\"pred\"] == results_df[\"label\"]\n",
        "\n",
        "# Menghitung precision, recall, dan f1-score untuk masing-masing kelas\n",
        "report = classification_report(\n",
        "    results_df[\"label\"],\n",
        "    results_df[\"pred\"],\n",
        "    labels=results_df[\"label\"].unique(),  # Memastikan semua label muncul di laporan\n",
        "    zero_division=0\n",
        ")\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "Zt9Sa1hhOsTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "# Menambahkan kolom 'result' untuk mengevaluasi apakah prediksi benar atau salah\n",
        "results_df[\"result\"] = results_df[\"pred\"] == results_df[\"label\"]\n",
        "\n",
        "# Menentukan urutan kelas dari A-Y\n",
        "classes = sorted(results_df[\"label\"].unique())  # Mengurutkan kelas dari A hingga Y\n",
        "\n",
        "# Menghitung precision, recall, dan f1-score untuk masing-masing kelas\n",
        "report = classification_report(\n",
        "    results_df[\"label\"],\n",
        "    results_df[\"pred\"],\n",
        "    labels=classes,  # Menambahkan urutan kelas\n",
        "    zero_division=0\n",
        ")\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Menambahkan nilai rata-rata precision, recall, f1-score\n",
        "precision_avg = precision_score(results_df[\"label\"], results_df[\"pred\"], average='macro', zero_division=0)\n",
        "recall_avg = recall_score(results_df[\"label\"], results_df[\"pred\"], average='macro', zero_division=0)\n",
        "f1_avg = f1_score(results_df[\"label\"], results_df[\"pred\"], average='macro', zero_division=0)\n",
        "\n",
        "print(\"\\nAverage Metrics:\")\n",
        "print(f\"Precision (average): {precision_avg:.4f}\")\n",
        "print(f\"Recall (average): {recall_avg:.4f}\")\n",
        "print(f\"F1 Score (average): {f1_avg:.4f}\")\n"
      ],
      "metadata": {
        "id": "oio_ZOrGPioA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengelompokkan hasil prediksi\n",
        "results_df[\"result\"] = np.where(\n",
        "    results_df.pred == results_df.label,\n",
        "    \"correct\",\n",
        "    np.where(results_df.pred.isin([\"empty\", \"n/a\"]), \"not found\", \"incorrect\")\n",
        ")\n",
        "\n",
        "# Mengatur urutan kategori untuk kolom 'result'\n",
        "results_df[\"result\"] = pd.Categorical(\n",
        "    results_df[\"result\"],\n",
        "    categories=[\"not found\", \"incorrect\", \"correct\"],\n",
        "    ordered=True\n",
        ")\n",
        "\n",
        "# Membuat urutan kategori dari A hingga Y\n",
        "label_order = sorted(results_df[\"label\"].unique())  # Menyortir label secara alfabetis\n",
        "\n",
        "# Mengubah kolom 'label' menjadi kategori dengan urutan yang sudah ditentukan\n",
        "results_df[\"label\"] = pd.Categorical(results_df[\"label\"], categories=label_order, ordered=True)\n",
        "\n",
        "# Atur gaya dan tema seaborn\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "sns.set_palette(\"pastel\")\n",
        "\n",
        "# Membuat histogram dengan seaborn\n",
        "plt.figure(figsize=(12, 8))\n",
        "ax = sns.histplot(\n",
        "    data=results_df,\n",
        "    x=\"label\",\n",
        "    hue=\"result\",\n",
        "    multiple=\"stack\",\n",
        "    stat=\"count\",\n",
        "    palette={\"correct\": \"mediumseagreen\", \"incorrect\": \"coral\", \"not found\": \"gray\"},  # Urutan warna sesuai kategori\n",
        "    legend=True\n",
        ")\n",
        "\n",
        "# Menambahkan judul dan label\n",
        "plt.title(\"Prediction Results by Label\", fontsize=16)\n",
        "plt.xlabel(\"Labels\", fontsize=14)\n",
        "plt.ylabel(\"Count\", fontsize=14)\n",
        "\n",
        "# Menampilkan legenda secara eksplisit\n",
        "plt.legend(\n",
        "    title=\"Result\",\n",
        "    title_fontsize=14,\n",
        "    fontsize=12,\n",
        "    loc=\"upper right\",\n",
        "    labels=[\"Correct\", \"Incorrect\", \"Not Found\"]  # Disesuaikan dengan urutan kategori\n",
        ")\n",
        "\n",
        "# Menyimpan grafik\n",
        "plt.savefig(\"prediction_results_with_ordered_labels.png\", bbox_inches=\"tight\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tbyrKa52mzuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.query(\"result == 'not found'\").groupby(\n",
        "    \"label\"\n",
        ").pred.value_counts().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "JMKD_8ubopRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_data.gen_tf_dataset(batch_size=train_data.size)\n",
        "xy = train_ds.take(1).get_single_element()\n",
        "\n",
        "embeddings, classes_onehot = xy[0].numpy(), xy[1].numpy()  # type: ignore\n",
        "class_indices = np.argmax(classes_onehot, axis=1)\n",
        "\n",
        "print(embeddings.shape, class_indices.shape)\n",
        "# -> (1861, 128) (1861,)"
      ],
      "metadata": {
        "id": "8FgDD3moo0FU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.manifold\n",
        "\n",
        "tsne = sklearn.manifold.TSNE()\n",
        "emb = tsne.fit_transform(embeddings)\n"
      ],
      "metadata": {
        "id": "G8HYUd1VQc1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "embdf = pd.DataFrame(emb, columns=[\"X1\", \"X2\"]).assign(label=class_indices)\n",
        "sns.scatterplot(\n",
        "    data=embdf, x=\"X1\", y=\"X2\", hue=\"label\", palette=\"Spectral\", legend=False\n",
        ")\n",
        "for i, c in enumerate(train_data.label_names):\n",
        "    if np.all(class_indices != i):\n",
        "        continue\n",
        "    center = emb[class_indices == i].mean(axis=0)\n",
        "    plt.annotate(c, center, center - 6)\n",
        "    plt.savefig(\"result.png\")\n"
      ],
      "metadata": {
        "id": "x_G9ankgQtiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "results_df[\"result\"] = np.where(\n",
        "    results_df.pred == results_df.label,\n",
        "    \"correct\",\n",
        "    np.where(results_df.pred.isin([\"n/a\", \"empty\"]), \"not found\", \"incorrect\"),\n",
        ")\n",
        "print(results_df.result.value_counts(normalize=True))\n",
        "sns.histplot(\n",
        "    data=results_df, x=\"label\", hue=\"result\", multiple=\"stack\", stat=\"count\"\n",
        ")"
      ],
      "metadata": {
        "id": "nNDm-tkhShMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "embdf = pd.DataFrame(emb, columns=[\"X1\", \"X2\"]).assign(label=class_indices)\n",
        "sns.scatterplot(\n",
        "    data=embdf, x=\"X1\", y=\"X2\", hue=\"label\", palette=\"Spectral\", legend=False\n",
        ")\n",
        "for i, c in enumerate(train_data.label_names):\n",
        "    if np.all(class_indices != i):\n",
        "        continue\n",
        "    center = emb[class_indices == i].mean(axis=0)\n",
        "    plt.annotate(c, center, center - 6)\n",
        "    plt.savefig(\"result.png\")\n"
      ],
      "metadata": {
        "id": "yEBdk--nS46v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}